{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Infrastructure Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import glob\n",
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import re\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "import paramiko\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of files with a given extension\n",
    "def get_files(filepath, file_extension):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root, file_extension))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to open the selected sheet\n",
    "def get_data_frame(sheet, workbook):\n",
    "    data = workbook[sheet]\n",
    "    data_values = data.values\n",
    "    ## To get the first line in file as a header line\n",
    "    columns = next(data_values)[0:]\n",
    "    ## To create a DataFrame based on the second and subsequent lines of data\n",
    "    data_frame = pd.DataFrame(data_values, columns = columns)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tables\n",
    "def create_tables(cur, conn):\n",
    "    for query in create_table_queries:\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "        except psycopg2.Error as e: \n",
    "            print(\"Error: Issue creating table\")\n",
    "            print (e)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables\n",
    "def drop_tables(cur, conn):\n",
    "    for name_table in drop_table_names:\n",
    "        drop_query = \"DROP table \" + name_table\n",
    "        try: \n",
    "            cur.execute(drop_query)\n",
    "        except psycopg2.Error as e: \n",
    "            print(\"Error: Dropping table\")\n",
    "            print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres conection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = psycopg2.connect(\"host=/cloudsql/bibmbo-maiz:us-central1:bimbo-maiz-db, user=luis password=qaz.wsx1 dbname=postgres\")\n",
    "#cur = conn.cursor()\n",
    "try: \n",
    "    #conn = psycopg2.connect(\"dbname=bimbomaiz user=luis password=postgres\")\n",
    "    conn = psycopg2.connect(dbname='etldb', user='postgres', password='qaz.wsx1', host='/cloudsql/etl-process-274514:us-central1:etlpg')\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)\n",
    "try: \n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not get cursor to the Database\")\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conection to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuario = 'ubuntu'\n",
    "pwd = '/home/luis/Documents/ETL/jupyter/AWS_conection/Jonh-test1.pem'\n",
    "enlace = '3.138.177.157'\n",
    "\n",
    "try:\n",
    "    hostname = enlace\n",
    "    myuser = usuario\n",
    "    mySSHK = pwd\n",
    "    sshcon = paramiko.SSHClient()  # will create the object\n",
    "    sshcon.set_missing_host_key_policy(paramiko.AutoAddPolicy()) # no known_hosts error\n",
    "    sshcon.connect(hostname, username=myuser, key_filename=mySSHK) # no passwd needed\n",
    "    sftp = sshcon.open_sftp()\n",
    "except:\n",
    "    print('\\n #### No se puede abrir la pagina, comprueba tu conexion a internet #### \\n')\n",
    "    \n",
    "### Conection to the CRM server\n",
    "#usuario = 'km'\n",
    "#pwd = 'H3pEq2n5YRqp5uLn#.'\n",
    "#enlace = '172.99.119.44'\n",
    "\n",
    "#try:\n",
    "#    client = paramiko.SSHClient()\n",
    "#    client.load_system_host_keys()\n",
    "#    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "#    trans = paramiko.Transport((enlace, 22))     \n",
    "#    trans.connect(username = usuario, password = pwd)\n",
    "    \n",
    "#    sftp = paramiko.SFTPClient.from_transport(trans)\n",
    "#except:\n",
    "#    print('\\n #### No se puede abrir la pagina, comprueba tu conexion a internet #### \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract general data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the directory where the data are located and to open the Excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option from local directory\n",
    "file_xlsx = get_files('/home/luis/Documents/ETL/jupyter', '*.xlsx')\n",
    "#file_xlsx \n",
    "## Opening the Excel Workbook \n",
    "workbook = openpyxl.load_workbook(filename = file_xlsx[0], read_only=True)\n",
    "#print(workbook.sheetnames, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option from google cloud storage\n",
    "# create storage client\n",
    "storage_client = storage.Client.from_service_account_json('/home/luis/Documents/ETL/jupyter/key/etl-process-5ef778cd27fb.json')\n",
    "bucket = storage_client.get_bucket('etl_bem_bitacoras_data')\n",
    "blob = bucket.blob('EXPORTAR.xlsx')\n",
    "downloaded_blob = blob.download_as_string()\n",
    "workbook = openpyxl.load_workbook(filename = BytesIO(downloaded_blob), read_only=True)\n",
    "#print(workbook.sheetnames, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bitacoras_csv = get_data_frame('01_caracteristicas Bitácora', workbook)\n",
    "#print(bitacoras_csv.head())\n",
    "#print(data_bitacoras_raw.columns)\n",
    "bitacoras_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of dataframe rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the id to make the subset from the project bitacoras\n",
    "#bitacoras_subset = pd.read_csv(\"bitacoras_subset.csv\")\n",
    "#bitacoras_subset\n",
    "\n",
    "## Transform the dataframe into a list\n",
    "#bitacoras_subset = bitacoras_subset['Id_bitacora'].tolist()\n",
    "\n",
    "## Get the rows to use\n",
    "#bitacoras_row = bitacoras_csv[bitacoras_csv['ID de la bitácora (clave primaria)'].isin(bitacoras_subset)]\n",
    "\n",
    "#bitacoras_row.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "bitacoras_columns = ['ID de la bitácora (clave primaria)',\n",
    "       'Tipo de bitácora (para módulo, áreas de extensión o áreas de impacto)',\n",
    "       'Año', 'Ciclo agronómico', 'Tipo de producción','ID de la parcela (clave foránea)',\n",
    "       'ID del Productor (clave foránea)', 'Nombre de la institución']\n",
    "\n",
    "bitacoras_raw = bitacoras_csv[bitacoras_columns]\n",
    "bitacoras_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotefile = '/var/www/html/reportes/Resumen_bitacorasETL.txt'\n",
    "\n",
    "# Get the file using the conection \n",
    "bitacorasCRM_f_in = sftp.file(remotefile, \"r\")\n",
    "bitacorasCRM_c_in = bitacorasCRM_f_in.read()\n",
    "bitacorasCRM_f_in.close()\n",
    "\n",
    "#From bites to dataframe\n",
    "bitacorasCRM_str = str(bitacorasCRM_c_in,'utf-8')\n",
    "bitacorasCRM_data = StringIO(bitacorasCRM_str) \n",
    "bitacorasCRM_df_na = pd.read_csv(bitacorasCRM_data , sep = \"\\t\")\n",
    "#productores_df_complete.to_csv(\"productores_df_complete.csv\", encoding = 'windows-1252', index = False)\n",
    "\n",
    "\n",
    "bitacorasCRM_df_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for local connection \n",
    "bitacorasCRM_df_na = pd.read_csv(\"/home/luis/Documents/ETL/jupyter/AWS_files/Resumen_bitacorasETL.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacorasCRM_df_na.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacorasCRM_columns = ['ID de bitacora', 'Tipo de bitacora',\n",
    "       'Anio Bitacora', 'Ciclo', 'Regimen hidrico', 'ID parcela',\n",
    "       'ID del productor', 'Proyecto']\n",
    "\n",
    "bitacorasCRM_df_raw = bitacorasCRM_df_na[bitacorasCRM_columns]\n",
    "# Delete NA\n",
    "bitacorasCRM_raw = bitacorasCRM_df_raw.dropna(subset=['ID de bitacora'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting NAs\n",
    "bitacoras_duplicate = bitacoras_raw.dropna(subset=['ID de la bitácora (clave primaria)'])\n",
    "\n",
    "## Dropping duplicates\n",
    "bitacoras_tipo = bitacoras_duplicate.drop_duplicates(subset = 'ID de la bitácora (clave primaria)') \n",
    "\n",
    "#bitacoras.shape\n",
    "#bitacoras.groupby('Tipo de producción').count()[['ID de la bitácora (clave primaria)']]\n",
    "\n",
    "## Standarize type of production by water availability\n",
    "bitacoras_tipo.loc[bitacoras_tipo['Tipo de producción'] == 'Punta de riego', 'Tipo de producción'] = 'Riego'\n",
    "#bitacoras.groupby('Tipo de producción').count()[['ID de la bitácora (clave primaria)']]\n",
    "\n",
    "## Changing NaN values to None\n",
    "bitacoras = bitacoras_tipo.where(pd.notnull(bitacoras_tipo), None)\n",
    "bitacoras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacorasCRM_raw['Ciclo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bitacoras(\n",
    "        bitacora_id int PRIMARY KEY,\n",
    "        tipo_bitacora varchar NOT NULL, \n",
    "        ao int NOT NULL,\n",
    "        ciclo_agronomico varchar NOT NULL,\n",
    "        tipo_produccion varchar NOT NULL,\n",
    "        parcela_id int NOT NULL,\n",
    "        productor_id int,\n",
    "        institucion_nombre varchar NOT NULL);\n",
    "\"\"\")\n",
    "\n",
    "# Insert queries\n",
    "bitacoras_table_insert = (\"\"\"\n",
    "    INSERT INTO bitacoras (bitacora_id, tipo_bitacora, ao, ciclo_agronomico, tipo_produccion,  parcela_id, \n",
    "    productor_id, institucion_nombre)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (bitacora_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute create tables queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [bitacoras_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in bitacoras.iterrows():\n",
    "    #print(list(row))\n",
    "    cur.execute(bitacoras_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parcelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelas_csv = get_data_frame('04_parcelas', workbook)\n",
    "#print(parcelas_csv.tail())\n",
    "#print(parcelas_csv.columns)\n",
    "parcelas_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get the id to make the subset\n",
    "file_parcelas_drop = pd.read_csv(\"infrastructure_parcelas_drop.csv\")\n",
    "#parcelas_drop\n",
    "\n",
    "## Transform the dataframe into a list\n",
    "parcelas_drop = file_parcelas_drop['parcela_id'].tolist()\n",
    "\n",
    "## Drop rows from the list\n",
    "parcelas_row = parcelas_csv[parcelas_csv['ID de la parcela (clave primaria)'].isin(parcelas_drop)== False]\n",
    "parcelas_row.reset_index(inplace = True)\n",
    "#parcelas_row.columns\n",
    "parcelas_row.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of rows that are in the bitacoras dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop parcelas are not in bitacoras\n",
    "bitacoras_par = bitacoras['ID de la parcela (clave foránea)'].tolist()\n",
    "#bitacoras_row = bitacoras_csv[bitacoras_csv['ID de la bitácora (clave primaria)'].isin(bitacoras_subset)]\n",
    "\n",
    "parcelas_bit = parcelas_row[parcelas_row['ID de la parcela (clave primaria)'].isin(bitacoras_par)]\n",
    "parcelas_bit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "parcelas_columns = ['ID de la parcela (clave primaria)','Superficie (ha)', \n",
    "                    'Tipo de parcela (módulo, área de extensión o área de impacto)', 'Estado', \n",
    "                    'Municipio', 'Localidad',  'Nombre del Hub', 'Latitud N', 'Longitud W']\n",
    "\n",
    "parcelas_columns = parcelas_bit[parcelas_columns]\n",
    "parcelas_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NA and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting NAs\n",
    "parcelas_na = parcelas_columns.dropna(subset=['ID de la parcela (clave primaria)'])\n",
    "\n",
    "## Dropping duplicates\n",
    "parcelas = parcelas_na.drop_duplicates(subset = 'ID de la parcela (clave primaria)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace incorrect coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get ccorrect coordinates\n",
    "coordenadas_corection = pd.read_csv('coordenadas_correction.csv')\n",
    "coordenadas_corection\n",
    "\n",
    "## Transform dataframe latitude column into dictionary\n",
    "latitud = dict()\n",
    "for n in range(0, coordenadas_corection.shape[0]): latitud[coordenadas_corection.iloc[n,0]] = coordenadas_corection.iloc[n,1]\n",
    "#df['first_name'] = df['ID'].apply(lambda x: first_name.get(x, df.loc[df['ID'] == x, 'first_name'].values[0]))\n",
    "parcelas['Latitud N'] = parcelas['ID de la parcela (clave primaria)'].apply(lambda x: latitud.get(x, parcelas.loc[parcelas['ID de la parcela (clave primaria)'] == x, 'Latitud N'].values[0]))\n",
    "\n",
    "\n",
    "## Transform dataframe longitude column into dictionary\n",
    "longitud = dict()\n",
    "for n in range(0, coordenadas_corection.shape[0]): longitud[coordenadas_corection.iloc[n,0]] = coordenadas_corection.iloc[n,2]\n",
    "parcelas['Longitud W'] = parcelas['ID de la parcela (clave primaria)'].apply(lambda x: longitud.get(x, parcelas.loc[parcelas['ID de la parcela (clave primaria)'] == x, 'Longitud W'].values[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelas_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS parcelas(\n",
    "        parcela_id int PRIMARY KEY,\n",
    "        superficie_ha real NOT NULL,\n",
    "        tipo_parcela varchar NOT NULL, \n",
    "        estado varchar NOT NULL,\n",
    "        municipio varchar NOT NULL,\n",
    "        localidad varchar NOT NULL,\n",
    "        hub varchar NOT NULL,\n",
    "        latitud_n real NOT NULL,\n",
    "        longitud_w real NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries insert \n",
    "parcelas_table_insert = (\"\"\"\n",
    "    INSERT INTO parcelas (parcela_id, superficie_ha, tipo_parcela , estado, municipio, localidad, \n",
    "    hub, latitud_n, longitud_w)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (parcela_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [parcelas_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in parcelas.iterrows():\n",
    "    #print(list(row))\n",
    "    cur.execute(parcelas_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables\n",
    "drop_table_names = ['bitacoras']\n",
    "drop_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Superficie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract siembra-resiembra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siembra_superficie_csv = get_data_frame('12_siembra Resiembra_general', workbook)\n",
    "#print(siembra_resiembra_csv.tail())\n",
    "#print(siembra_resiembra_csv.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows by filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter siembra\n",
    "siembra_superficie_drop = siembra_superficie_csv[(siembra_superficie_csv['Nombre de la sección'] == 'C. SIEMBRA') & (siembra_superficie_csv['Tipo de parcela (testigo o innovación)'] == 'Parcela innovación')]\n",
    "siembra_superficie_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop siembra rows that are not in bitacoras\n",
    "bitacoras_siem = bitacoras['ID de la bitácora (clave primaria)'].tolist()\n",
    "#bitacoras_row = bitacoras_csv[bitacoras_csv['ID de la bitácora (clave primaria)'].isin(bitacoras_subset)]\n",
    "\n",
    "siembra_superficie_bit = siembra_superficie_drop[siembra_superficie_drop['ID de la bitácora (clave foránea)'].isin(bitacoras_siem)]\n",
    "siembra_superficie_bit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "#siembra_superficie_columns = ['ID de la bitácora (clave foránea)',\n",
    "#       'ID de tipo de bitácora (clave foránea)',\n",
    "#       'Tipo de parcela (testigo o innovación)',\n",
    "#       'Nombre de la sección', 'Superficie sembrada ($/ha)']\n",
    "\n",
    "siembra_superficie_columns = ['ID de la bitácora (clave foránea)', 'Superficie sembrada ($/ha)']\n",
    "\n",
    "siembra_superficie = siembra_superficie_bit[siembra_superficie_columns]\n",
    "siembra_superficie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform siembra_resiembra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting NAs\n",
    "#siembra_superficie_na = siembra_superficie_columns.dropna(subset=['ID de tipo de bitácora (clave foránea)'])\n",
    "#siembra_na.shape\n",
    "#siembra_superficie_na.tail()\n",
    "\n",
    "## Dropping duplicates\n",
    "#siembra_superficie = siembra_superficie_na.drop_duplicates(subset = 'ID de tipo de bitácora (clave foránea)') \n",
    "#siembra_superficie.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting superficie by bitacora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the superficie data from parcelas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_superficie = bitacoras[['ID de la bitácora (clave primaria)', 'ID de la parcela (clave foránea)']]\n",
    "parcelas_superficie = parcelas[['ID de la parcela (clave primaria)', 'Superficie (ha)']]\n",
    "\n",
    "superficie_bit_par = pd.merge(left=bitacoras_superficie, right= parcelas_superficie, how='inner', left_on =  'ID de la parcela (clave foránea)', right_on = 'ID de la parcela (clave primaria)')\n",
    "superficie_bit_par.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the superficie data from siembra when the plot is a modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform dataframe superficie column into dictionary\n",
    "dict_siembra_sup = dict()\n",
    "for n in range(0, siembra_superficie.shape[0]): dict_siembra_sup[siembra_superficie.iloc[n,0]] = siembra_superficie.iloc[n,1]\n",
    "    \n",
    "#df['first_name'] = df['ID'].apply(lambda x: first_name.get(x, df.loc[df['ID'] == x, 'first_name'].values[0]))\n",
    "superficie_bit_par['Superficie (ha)'] = superficie_bit_par['ID de la bitácora (clave primaria)'].apply(lambda x: dict_siembra_sup.get(x, superficie_bit_par.loc[superficie_bit_par['ID de la bitácora (clave primaria)'] == x, 'Superficie (ha)'].values[0]))\n",
    "superficie_bit_par[superficie_bit_par['ID de la bitácora (clave primaria)'] == dict_siembra_sup]\n",
    "\n",
    "superficie_bitacora_parcela = superficie_bit_par[['ID de la bitácora (clave primaria)', 'Superficie (ha)']]\n",
    "superficie_bitacora_parcela.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "superficie_bitacora_parcela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load siembra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superficie_bit_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS superficie_bit(\n",
    "        bitacora_id int PRIMARY KEY,\n",
    "        superficie_sembrada_ha real NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries insert\n",
    "superficie_bit_table_insert = (\"\"\"\n",
    "    INSERT INTO superficie_bit(bitacora_id, superficie_sembrada_ha)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (bitacora_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [superficie_bit_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in superficie_bitacora_parcela.iterrows():\n",
    "    print(list(row))\n",
    "    cur.execute(superficie_bit_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT to_json(infraestructure_q) FROM (SELECT bitacoras.bitacora_id, bitacoras.ao, bitacoras.ciclo_agronomico, \\\n",
    "    bitacoras.tipo_produccion, bitacoras.parcela_id, bitacoras.institucion_nombre, parcelas.parcela_id,\\\n",
    "    parcelas.tipo_parcela,  parcelas.estado,  parcelas.municipio,  parcelas.localidad, parcelas.latitud_n,\\\n",
    "    parcelas.longitud_w, superficie_bit.bitacora_id, superficie_bit.superficie_sembrada_ha \\\n",
    "    FROM bitacoras INNER JOIN parcelas ON bitacoras.parcela_id = parcelas.parcela_id \\\n",
    "    INNER JOIN  superficie_bit ON bitacoras.bitacora_id = superficie_bit.bitacora_id) infraestructure_q LIMIT 5\")\n",
    "# bitacora_id, tipo_bitacora, ao, ciclo_agronomico, tipo_produccion,  parcela_id, productor_id, institucion_nombre\n",
    "\n",
    "row = cur.fetchall()\n",
    "    #while row:\n",
    "#return jsonify(row)\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT bitacoras.bitacora_id, bitacoras.ao, bitacoras.ciclo_agronomico, \\\n",
    "    bitacoras.tipo_produccion, bitacoras.parcela_id, bitacoras.institucion_nombre, parcelas.parcela_id,\\\n",
    "    parcelas.tipo_parcela,  parcelas.estado,  parcelas.municipio,  parcelas.localidad, parcelas.latitud_n,\\\n",
    "    parcelas.longitud_w, superficie_bit.bitacora_id, superficie_bit.superficie_sembrada_ha \\\n",
    "    FROM bitacoras INNER JOIN parcelas ON bitacoras.parcela_id = parcelas.parcela_id \\\n",
    "    INNER JOIN  superficie_bit ON bitacoras.bitacora_id = superficie_bit.bitacora_id LIMIT 5\")\n",
    "row = cur.fetchall()\n",
    "    #while row:\n",
    "#return jsonify(row)\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop tables\n",
    "drop_table_names = ['test_table_2']\n",
    "drop_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert queries\n",
    "bitacoras_table_insert = (\"\"\"\n",
    "    INSERT INTO bitacora (bitacora_id, tipo_bitacora, institucion)\n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (bitacora_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_bitacoras.iterrows():\n",
    "    print(list(row))\n",
    "    cur.execute(bitacoras_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test table\n",
    "test_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS test_table(\n",
    "        test_id int PRIMARY KEY,\n",
    "        num real NOT NULL,\n",
    "        text varchar NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [test_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test table\n",
    "test_table_2_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS test_table_2(\n",
    "        test_id int PRIMARY KEY,\n",
    "        num real NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [test_table_2_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data\n",
    "test_table_insert = (\"\"\"\n",
    "    INSERT INTO test_table(test_id, num, text)\n",
    "    VALUES (%s, %s, %s)\n",
    "    ON CONFLICT (test_id) DO UPDATE SET (num, text)\n",
    "            = (EXCLUDED.num, EXCLUDED.text);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [3,3,'three']\n",
    "cur.execute(test_table_insert, list(row))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data\n",
    "test_table_2_insert = (\"\"\"\n",
    "    INSERT INTO test_table_2(test_id, num)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (test_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [1,1]\n",
    "cur.execute(test_table_2_insert, list(row))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_par = cur.execute('''SELECT parcela_id FROM bitacoras;''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database conection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(user=DATABASE_USER, password=PASSWORD,\n",
    "                        host='localhost', port='5432')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
