{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Infrastructure Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import glob\n",
    "import os\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import re\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "import os\n",
    "import paramiko\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of files with a given extension\n",
    "def get_files(filepath, file_extension):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root, file_extension))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to open the selected sheet\n",
    "def get_data_frame(sheet, workbook):\n",
    "    data = workbook[sheet]\n",
    "    data_values = data.values\n",
    "    ## To get the first line in file as a header line\n",
    "    columns = next(data_values)[0:]\n",
    "    ## To create a DataFrame based on the second and subsequent lines of data\n",
    "    data_frame = pd.DataFrame(data_values, columns = columns)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tables\n",
    "def create_tables(cur, conn):\n",
    "    for query in create_table_queries:\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "        except psycopg2.Error as e: \n",
    "            print(\"Error: Issue creating table\")\n",
    "            print (e)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres conection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not make connection to the Postgres database\n",
      "could not connect to server: No such file or directory\n",
      "\tIs the server running locally and accepting\n",
      "\tconnections on Unix domain socket \"/cloudsql/etl-process-274514:us-central1:etlpg/.s.PGSQL.5432\"?\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6115692ef226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: Could not get cursor to the Database\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "#conn = psycopg2.connect(\"host=/cloudsql/bibmbo-maiz:us-central1:bimbo-maiz-db, user=luis password=qaz.wsx1 dbname=postgres\")\n",
    "#cur = conn.cursor()\n",
    "try: \n",
    "    #conn = psycopg2.connect(\"dbname=bimbomaiz user=luis password=postgres\")\n",
    "    conn = psycopg2.connect(dbname='etldb', user='postgres', password='qaz.wsx1', host='/cloudsql/etl-process-274514:us-central1:etlpg')\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not make connection to the Postgres database\")\n",
    "    print(e)\n",
    "try: \n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e: \n",
    "    print(\"Error: Could not get cursor to the Database\")\n",
    "    print(e)\n",
    "\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conection to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuario = 'ubuntu'\n",
    "pwd = '/home/luis/Documents/ETL/jupyter/AWS_conection/Jonh-test1.pem'\n",
    "enlace = '3.138.177.157'\n",
    "\n",
    "try:\n",
    "    hostname = enlace\n",
    "    myuser = usuario\n",
    "    mySSHK = pwd\n",
    "    sshcon = paramiko.SSHClient()  # will create the object\n",
    "    sshcon.set_missing_host_key_policy(paramiko.AutoAddPolicy()) # no known_hosts error\n",
    "    sshcon.connect(hostname, username=myuser, key_filename=mySSHK) # no passwd needed\n",
    "    sftp = sshcon.open_sftp()\n",
    "except:\n",
    "    print('\\n #### No se puede abrir la pagina, comprueba tu conexion a internet #### \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract general data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the directory where the data are located and to open the Excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option from google cloud storage\n",
    "# create storage client\n",
    "storage_client = storage.Client.from_service_account_json('/home/luis/Documents/ETL/jupyter/key/etl-process-5ef778cd27fb.json')\n",
    "bucket = storage_client.get_bucket('etl_bem_bitacoras_data')\n",
    "blob = bucket.blob('EXPORTAR.xlsx')\n",
    "downloaded_blob = blob.download_as_string()\n",
    "workbook = openpyxl.load_workbook(filename = BytesIO(downloaded_blob), read_only=True)\n",
    "#print(workbook.sheetnames, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bitacoras_csv = get_data_frame('01_caracteristicas Bitácora', workbook)\n",
    "bitacoras_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "bitacoras_columns = ['ID de la bitácora (clave primaria)',\n",
    "       'Tipo de bitácora (para módulo, áreas de extensión o áreas de impacto)',\n",
    "       'Año', 'Ciclo agronómico', 'Tipo de producción','ID de la parcela (clave foránea)',\n",
    "       'ID del Productor (clave foránea)', 'Nombre de la institución']\n",
    "\n",
    "bitacoras_raw = bitacoras_csv[bitacoras_columns]\n",
    "bitacoras_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remotefile = '/var/www/html/reportes/Resumen_bitacorasETL.txt'\n",
    "\n",
    "# Get the file using the conection \n",
    "bitacorasCRM_f_in = sftp.file(remotefile, \"r\")\n",
    "bitacorasCRM_c_in = bitacorasCRM_f_in.read()\n",
    "bitacorasCRM_f_in.close()\n",
    "\n",
    "#From bites to dataframe\n",
    "bitacorasCRM_str = str(bitacorasCRM_c_in,'utf-8')\n",
    "bitacorasCRM_data = StringIO(bitacorasCRM_str) \n",
    "bitacorasCRM_df_na = pd.read_csv(bitacorasCRM_data , sep = \"\\t\")\n",
    "#productores_df_complete.to_csv(\"productores_df_complete.csv\", encoding = 'windows-1252', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for local connection \n",
    "bitacorasCRM_df_na = pd.read_csv(\"/home/luis/Documents/ETL/jupyter/AWS_files/Resumen_bitacorasETL.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacorasCRM_columns = ['ID de bitacora', 'Tipo de bitacora',\n",
    "       'Anio Bitacora', 'Ciclo', 'Regimen hidrico', 'ID parcela',\n",
    "       'ID del productor', 'Proyecto']\n",
    "\n",
    "bitacorasCRM_df_raw = bitacorasCRM_df_na[bitacorasCRM_columns]\n",
    "# Delete NA\n",
    "bitacorasCRM_raw = bitacorasCRM_df_raw.dropna(subset=['ID de bitacora'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting NAs\n",
    "bitacoras_duplicate = bitacoras_raw.dropna(subset=['ID de la bitácora (clave primaria)'])\n",
    "\n",
    "## Dropping duplicates\n",
    "bitacoras_tipo = bitacoras_duplicate.drop_duplicates(subset = 'ID de la bitácora (clave primaria)') \n",
    "\n",
    "#bitacoras.shape\n",
    "#bitacoras.groupby('Tipo de producción').count()[['ID de la bitácora (clave primaria)']]\n",
    "\n",
    "## Standarize type of production by water availability\n",
    "bitacoras_tipo.loc[bitacoras_tipo['Tipo de producción'] == 'Punta de riego', 'Tipo de producción'] = 'Riego'\n",
    "#bitacoras.groupby('Tipo de producción').count()[['ID de la bitácora (clave primaria)']]\n",
    "\n",
    "## Changing NaN values to None\n",
    "bitacoras = bitacoras_tipo.where(pd.notnull(bitacoras_tipo), None)\n",
    "bitacoras.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacorasCRM_raw['Ciclo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load bitacoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bitacoras(\n",
    "        bitacora_id int PRIMARY KEY,\n",
    "        tipo_bitacora varchar NOT NULL, \n",
    "        ao int NOT NULL,\n",
    "        ciclo_agronomico varchar NOT NULL,\n",
    "        tipo_produccion varchar NOT NULL,\n",
    "        parcela_id int NOT NULL,\n",
    "        productor_id int,\n",
    "        institucion_nombre varchar NOT NULL);\n",
    "\"\"\")\n",
    "\n",
    "# Insert queries\n",
    "bitacoras_table_insert = (\"\"\"\n",
    "    INSERT INTO bitacoras (bitacora_id, tipo_bitacora, ao, ciclo_agronomico, tipo_produccion,  parcela_id, \n",
    "    productor_id, institucion_nombre)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (bitacora_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute create tables queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [bitacoras_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in bitacoras.iterrows():\n",
    "    #print(list(row))\n",
    "    cur.execute(bitacoras_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parcelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelas_csv = get_data_frame('04_parcelas', workbook)\n",
    "#print(parcelas_csv.tail())\n",
    "#print(parcelas_csv.columns)\n",
    "parcelas_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get the id to make the subset\n",
    "file_parcelas_drop = pd.read_csv(\"infrastructure_parcelas_drop.csv\")\n",
    "\n",
    "## Transform the dataframe into a list\n",
    "parcelas_drop = file_parcelas_drop['parcela_id'].tolist()\n",
    "\n",
    "## Drop rows from the list\n",
    "parcelas_row = parcelas_csv[parcelas_csv['ID de la parcela (clave primaria)'].isin(parcelas_drop)== False]\n",
    "parcelas_row.reset_index(inplace = True)\n",
    "#parcelas_row.columns\n",
    "parcelas_row.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of rows that are in the bitacoras dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop parcelas are not in bitacoras\n",
    "bitacoras_par = bitacoras['ID de la parcela (clave foránea)'].tolist()\n",
    "#bitacoras_row = bitacoras_csv[bitacoras_csv['ID de la bitácora (clave primaria)'].isin(bitacoras_subset)]\n",
    "\n",
    "parcelas_bit = parcelas_row[parcelas_row['ID de la parcela (clave primaria)'].isin(bitacoras_par)]\n",
    "parcelas_bit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "parcelas_columns = ['ID de la parcela (clave primaria)','Superficie (ha)', \n",
    "                    'Tipo de parcela (módulo, área de extensión o área de impacto)', 'Estado', \n",
    "                    'Municipio', 'Localidad',  'Nombre del Hub', 'Latitud N', 'Longitud W']\n",
    "\n",
    "parcelas_columns = parcelas_bit[parcelas_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NA and duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting NAs\n",
    "parcelas_na = parcelas_columns.dropna(subset=['ID de la parcela (clave primaria)'])\n",
    "\n",
    "## Dropping duplicates\n",
    "parcelas = parcelas_na.drop_duplicates(subset = 'ID de la parcela (clave primaria)') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace incorrect coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get ccorrect coordinates\n",
    "coordenadas_corection = pd.read_csv('coordenadas_correction.csv')\n",
    "coordenadas_corection\n",
    "\n",
    "## Transform dataframe latitude column into dictionary\n",
    "latitud = dict()\n",
    "for n in range(0, coordenadas_corection.shape[0]): latitud[coordenadas_corection.iloc[n,0]] = coordenadas_corection.iloc[n,1]\n",
    "#df['first_name'] = df['ID'].apply(lambda x: first_name.get(x, df.loc[df['ID'] == x, 'first_name'].values[0]))\n",
    "parcelas['Latitud N'] = parcelas['ID de la parcela (clave primaria)'].apply(lambda x: latitud.get(x, parcelas.loc[parcelas['ID de la parcela (clave primaria)'] == x, 'Latitud N'].values[0]))\n",
    "\n",
    "\n",
    "## Transform dataframe longitude column into dictionary\n",
    "longitud = dict()\n",
    "for n in range(0, coordenadas_corection.shape[0]): longitud[coordenadas_corection.iloc[n,0]] = coordenadas_corection.iloc[n,2]\n",
    "parcelas['Longitud W'] = parcelas['ID de la parcela (clave primaria)'].apply(lambda x: longitud.get(x, parcelas.loc[parcelas['ID de la parcela (clave primaria)'] == x, 'Longitud W'].values[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parcelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelas_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS parcelas(\n",
    "        parcela_id int PRIMARY KEY,\n",
    "        superficie_ha real NOT NULL,\n",
    "        tipo_parcela varchar NOT NULL, \n",
    "        estado varchar NOT NULL,\n",
    "        municipio varchar NOT NULL,\n",
    "        localidad varchar NOT NULL,\n",
    "        hub varchar NOT NULL,\n",
    "        latitud_n real NOT NULL,\n",
    "        longitud_w real NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries insert \n",
    "parcelas_table_insert = (\"\"\"\n",
    "    INSERT INTO parcelas (parcela_id, superficie_ha, tipo_parcela , estado, municipio, localidad, \n",
    "    hub, latitud_n, longitud_w)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (parcela_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [parcelas_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in parcelas.iterrows():\n",
    "    #print(list(row))\n",
    "    cur.execute(parcelas_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Superficie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract siembra-resiembra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siembra_superficie_csv = get_data_frame('12_siembra Resiembra_general', workbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows by filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter siembra\n",
    "siembra_superficie_drop = siembra_superficie_csv[(siembra_superficie_csv['Nombre de la sección'] == 'C. SIEMBRA') & (siembra_superficie_csv['Tipo de parcela (testigo o innovación)'] == 'Parcela innovación')]\n",
    "siembra_superficie_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop siembra rows that are not in bitacoras\n",
    "bitacoras_siem = bitacoras['ID de la bitácora (clave primaria)'].tolist()\n",
    "#bitacoras_row = bitacoras_csv[bitacoras_csv['ID de la bitácora (clave primaria)'].isin(bitacoras_subset)]\n",
    "\n",
    "siembra_superficie_bit = siembra_superficie_drop[siembra_superficie_drop['ID de la bitácora (clave foránea)'].isin(bitacoras_siem)]\n",
    "siembra_superficie_bit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of the columns to use\n",
    "siembra_superficie_columns = ['ID de la bitácora (clave foránea)', 'Superficie sembrada ($/ha)']\n",
    "\n",
    "siembra_superficie = siembra_superficie_bit[siembra_superficie_columns]\n",
    "siembra_superficie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting superficie by bitacora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the superficie data from parcelas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacoras_superficie = bitacoras[['ID de la bitácora (clave primaria)', 'ID de la parcela (clave foránea)']]\n",
    "parcelas_superficie = parcelas[['ID de la parcela (clave primaria)', 'Superficie (ha)']]\n",
    "\n",
    "superficie_bit_par = pd.merge(left=bitacoras_superficie, right= parcelas_superficie, how='inner', left_on =  'ID de la parcela (clave foránea)', right_on = 'ID de la parcela (clave primaria)')\n",
    "superficie_bit_par.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the superficie data from siembra when the plot is a modulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform dataframe superficie column into dictionary\n",
    "dict_siembra_sup = dict()\n",
    "for n in range(0, siembra_superficie.shape[0]): dict_siembra_sup[siembra_superficie.iloc[n,0]] = siembra_superficie.iloc[n,1]\n",
    "    \n",
    "#df['first_name'] = df['ID'].apply(lambda x: first_name.get(x, df.loc[df['ID'] == x, 'first_name'].values[0]))\n",
    "superficie_bit_par['Superficie (ha)'] = superficie_bit_par['ID de la bitácora (clave primaria)'].apply(lambda x: dict_siembra_sup.get(x, superficie_bit_par.loc[superficie_bit_par['ID de la bitácora (clave primaria)'] == x, 'Superficie (ha)'].values[0]))\n",
    "superficie_bit_par[superficie_bit_par['ID de la bitácora (clave primaria)'] == dict_siembra_sup]\n",
    "\n",
    "superficie_bitacora_parcela = superficie_bit_par[['ID de la bitácora (clave primaria)', 'Superficie (ha)']]\n",
    "superficie_bitacora_parcela.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "superficie_bitacora_parcela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load siembra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superficie_bit_table_create = (\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS superficie_bit(\n",
    "        bitacora_id int PRIMARY KEY,\n",
    "        superficie_sembrada_ha real NOT NULL);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries insert\n",
    "superficie_bit_table_insert = (\"\"\"\n",
    "    INSERT INTO superficie_bit(bitacora_id, superficie_sembrada_ha)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (bitacora_id) DO NOTHING;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "create_table_queries = [superficie_bit_table_create]\n",
    "create_tables(cur, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert values\n",
    "for i, row in superficie_bitacora_parcela.iterrows():\n",
    "    print(list(row))\n",
    "    cur.execute(superficie_bit_table_insert, list(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database conection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
